<p align="center"><h1> ОСНОВИ СИСТЕМ ШТУЧНОГО ІНТЕЛЕКТУ, НЕЙРОННИХ МЕРЕЖ та ГЛИБОКОГО НАВЧАННЯ<h1></p>

<p align="center"><h2> ЛЕКЦІЙНИЙ МАТЕРІАЛ</h2></p>

**Надані матеріали охоплюють шрокий спектр концепцій, методів та алгоритмів ML, DL, NN, що дозволяє оволодіти знаннями відповідного профілю на першому (бакалаврському) рівні.**

<p align="center"><h2>Орієнтовано на вивчання наступних дисциплін:</h2></p>

- ***Сучасні технології програмування*** [Syllabus](/ADDONS/Syllabus_01_Prog_Tech.md)
- ***Методи та системи штучного інтелекту***  [Syllabus](/ADDONS/Syllabus_02_AI_ML.md)
- ***Технології програмування систем штучного інтелекту***  [Syllabus](/ADDONS/Syllabus_03_TF.md)

<p align="center"><h2>Для спеціальностей IT напрямку:</h2></p>

- ***121 Інженерія програмного забезпечення***
- ***122 Комп’ютерні науки***
- ***123 Комп’ютерна інженерія***
- ***125 Кібербезпека***

<details>

<summary> <h2>Частина 1. Штучний інтелект та машинне навчання (AI, DL) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**1.1**|[**Введення в штучний інтелект (AI).](/Mod_01_/01_01_AI/Lec_01_01_.pdf) Історичний огляд, персоналії. Огляд завдань у сфері штучного інтелекту**| | |
|**1.2**|**Машинне навчання (DL): модель, навчання, інференс. Види машинного навчання**| | |
|**1.3**|**[Датасет](/Mod_01_/01_03_DATASET/Lec_01_03_.pdf). Поняття датасету. Організація датасету для машинного навчання. Генерація типових датасетів за допомогою Scikit-Learn**|[IRIS](/Mod_01_/01_03_DATASET/CODE_1_3_1/Lec_01_03_Exmpl_1_IRIS.md) [Blobs](/Mod_01_/01_03_DATASET/CODE_1_3_3/Lec_01_03_Exmpl_3_Blobs.md)|[SciKit](https://scikit-learn.org/stable/datasets.html) [TensorFlow](https://www.tensorflow.org/datasets/catalog/overview#all_datasets)|

</details>

<details>

<summary> <h2>Частина 2. Навчання з вчителем (Unsupervised Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**2.1**|**Регресія. Загальне визначення  задачі регресії. Типові постановки задачі регресії**| | |
|**2.2**|**Оцінка якості вирішення задачі регресії. Огляд методів вирішення задачі регресії**| | |
|**2.3**|**Приклад вирішення задачі лінійної регресії (Scikit-learn)**| | |
|**2.4**|**Приклад вирішення задачі поліноміальної регресії (Scikit-learn)**| | |
|**2.5**|**Класифікація. Загальне визначення задач класифікації. Типові постановки задачі класифікації**| | |
|**2.6**|**Оцінка якості вирішення задачі класифікації. Огляд методів вирішення задачі класифікації**| | |
|**2.7**|**Метод  kNN. Приклад вирішення задачі класифікації за допомогою kNN (Scikit-learn)**| | |
|**2.8**|**Метод  SVM. Приклад вирішення задачі класифікації за допомогою SVM (Scikit-learn)**| | |

</details>

<details>

<summary> <h2>Частина 3. Навчання без вчителя (самонавчання, Unsupervised Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**3.1**|**Кластеризація. Загальне визначення задач кластеризації. Типові варіанти постаноки задачі кластеризації**| | |
|**3.2**|**Оцінка якості вирішення задачі кластеризації. Огляд методів вирішення задачі кластеризації**| | |
|**3.3**|**Метод k-means. Приклад вирішення задачі кластеризації за допомогою k-means (Scikit-learn)**| | |
|**3.4**|**Метод DBSCAN. Приклад вирішення задачі кластеризації за допомогою DBSCAN (Scikit-learn)**| | |

</details>

<details>

<summary> <h2>Частина 4. Навчання з підкріпленням (Reinforcement Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**4.1**|**Вступ до навчання з підкріпленням. Головні концепції. Агенти.**| | |
|**4.2**|**Метод Монте-Карло. Приклад використання методу Монте-Карло для вирішення задачі теорії ігор (Python)**| | |

</details>

<details>

<summary> <h2>Частина 5. Глибоке навчання (Deep Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**5.1**|**Загальні відомості щодо нервової системи живих організмів. Природний нейрон. Синоптичний зв'язок нейронів. Правило Хебба. Штучний нейрон. Функція активації**| | |
|**5.2**|**Нейронні мережі. Нейронна мережа з одним прихованим шаром - персептрон.  Навчання персептрону. Приклад вирішення задачі класифікації за допомогою персептрону  (Python, Numpy)**| | |
|**5.3**|**Багатошаровий персептрон (MLP). Загальний підхід до навчання MLP. Пряме розповсюдження. Функція похибки. Зворотне розповсюдження.**| | |
|**5.4**|**Градієнтний метод зменшення похибки навчання. Автоматичне обчислення компонент градієнту. Основи оптимізації градієнтного спуску.**| | |
|**5.5**|**Основи побудови нейронних мереж з використанням модуля NumPy.**| | |
|**5.6**|**Вирішення задачі класифікації за допомогою MLP. Приклад класифікації рукописних цифр (датасет MNIST, Python, Numpy)**| | |
|**5.7**|**Сучасні системи штучного інтелекту, архітектури систем AI. Досягнення, перспективи, виклики.**| | |

</details>

<details>

<summary><h2>[Частина 6.](/Mod_06_/README_06.md) Високорівнева мова програмування Python</h2></summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**6.1**|**[Базові елементи високорівневої мови програмування.](/Mod_06_/06_01_/Lec_06_01_.pdf)**|[Приклад](/Mod_06_/06_01_/CODE_6_1/Lec_06_01_Exmpl.md) | |
|**6.2**|**[Загальні поняття колекції та складних структур даних.](/Mod_06_/06_02_/Lec_06_02_.pdf)**|[Приклад](/Mod_06_/06_02_/CODE_6_2/Lec_06_02_Exmpl.md) | |
|**6.3**|**[Файлові об’єкти. Визначення загальної структури програми.](/Mod_06_/06_03_/Lec_06_03_.pdf)**|[Приклад](/Mod_06_/06_03_/CODE_6_3/Lec_06_03_Exmpl.md) | |
|**6.4**|**[Функціональне програмування.](/Mod_06_/06_04_Lec_06_04_.pdf)**|[Приклад](/Mod_06_/06_01_/CODE_6_4/Lec_06_04_Exmpl.md) | |
|**6.5**|**[Інтерпретація скриптів. Модулі та типові пакети.](/Mod_06_/06_05_/Lec_06_05_.pdf)**|[Приклад](/Mod_06_/06_05_/CODE_6_5/Lec_06_05_Exmpl.md) | |
|**6.6**|**[Об’єктно-орієнтоване програмування. Проектування класів.](/Mod_06_/06_06_/Lec_06_06_.pdf)**|[Приклад](/Mod_06_/06_06_/CODE_6_6/Lec_06_06_Exmpl.md) | |
|**6.7**|**[Можливості перевантаження операторів. Визначення понять об’єктів ітерування, ітератора та генератора.](/Mod_06_/06_07_/Lec_06_07_.pdf)**|[Приклад](/Mod_06_/06_07_/CODE_6_7/Lec_06_07_Exmpl.md) | |
|**6.8**|**[Убудовані функції та вбудовані класи виняткових ситуацій.](/Mod_06_/06_08_/Lec_06_08_.pdf)**|[Приклад](/Mod_06_/06_08_/CODE_6_8/Lec_06_08_Exmpl.md) | |
|**6.9**|**[Базові бібліотечні модулі. Пакети для роботи зі штучним інтелектом.](/Mod_06_/06_09_/Lec_06_09_.pdf)**|[Приклад](/Mod_06_/06_09_/CODE_6_9/Lec_06_09_Exmpl.md) | |

</details>

<details>

<summary> <h2>Частина 7. Бібліотеки TensorFlow та KERAS  </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**7.1**|**[TensorFlow. Архітектура. Тензорні  об'єкти](/Mod_07_/07_01_TF/Lec_07_01.pdf)  Створення тензорів. Індексація тензорів.**|[Приклад 1](/Mod_07_/07_01_TF/CODE_7_1_1/lec_07_01_Exmpl_1.md) | |
|**7.2**|**TensorFlow. Базові операції із тензорами**| | |
|**7.3**|**TensorFlow. Поняття обчислювального графу. Використання графу для обчислень компонент градієнту під час зворотного поширення помилки. Типи обчислювальних графів, режими виконання. Створення "градієнтної стрічки"**| | |
|**7.4**|**TensorFlow. Загальна організація процесу навчання моделі. Мінімізація похибки навчання методом градієнтного спуску.**| | |
|**7.5**|**TensorFlow. Оптимізатори градієнтного спуску**| | |
|**7.6**|**Датасети. Ознаки, мітки. Пакети даних (batch). Тренувальний набір даних (training set). Валідаційний набір даних (validation set). Тестувальний набір даних (testing set)**| | |
|**7.7**|**TensorFlow. Вбудовані датасети та засоби TF доступу до даних.**| | |
|**7.8**|**Підготовка даних для використання в навчанні моделей. Типи даних. Кодування даних. Очищення даних. Оцінка якості даних**| | |
|**7.9**|**Вирішення задачі класифікації шляхом навчання моделі за алгоритмом kNN TensorFlow.**| | |
|**7.10**|**Вирішення задачі класифікації шляхом навчання моделі за алгоритмом SVM  TensorFlow**| | |
|**7.11**|**Вирішення задачі кластеризації шляхом самонавчання моделі за алгоритмом DBSCAN засобами TensorFlow**| | |
|**7.12**|**KERAS. Шари та моделі. Робота**| | |
|**7.13**|**Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами TensorFlow/KERAS**| | |
|**7.14**|**Вирішення задачі багато класової класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами TensorFlow/KERAS**| | |

</details>


<p align="center"><h2> Рекомендована література </h2></p>

- [Основна](ADDONS/Lit_Main.md)

- [Додаткова](ADDONS/Lit_Add.md)

- [Рекомендовані програмні засоби](ADDONS/Prog_Sys.md)


<p align="center"><h2> Надані навчальні матеріали охоплюють </h2></p>

1. Теоретичні відомості щодо теми, що розглядається, достатні для оволодіння базовими питаннями означеної теми;

2. Практичну реалізацію алгоритмів, що вивчаються (на мові Pyton) з використання відповідних бібліотек (Scikit-learn, Pandas, Tesorflow, Keras);

3. Приклади коду та блокноти Jupyter, які містять вказівки, що полегшують розуміння складних концепцій і експериментування з різними техніками;

4. Посилання на додаткові ресурси (статті, навчальні посібники та набори даних).
