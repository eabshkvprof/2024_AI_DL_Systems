# **ОСНОВИ СИСТЕМ ШТУЧНОГО ІНТЕЛЕКТУ, НЕЙРОННИХ МЕРЕЖ та ГЛИБОКОГО НАВЧАННЯ**

## **ЛЕКЦІЙНИЙ МАТЕРІАЛ**
Надані матеріали охоплюють шрокий спектр концепцій, методів та алгоритмів ML, DL, NN, що дозволяє оволодіти знаннями відповідного профілю на першому (бакалаврському) рівні.

### Орієнтовано на спеціальності:
- ***121 Інженерія програмного забезпечення***
- ***122 Комп’ютерні науки***
- ***123 Комп’ютерна інженерія***
- ***125 Кібербезпека***

### **Частина 1. Штучний інтелект та машинне навчання (AI, DL)**

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**1.1**|**Введення в штучний інтелект (AI). Історичний огляд, персоналії. Огляд завдань царині штучного інтелекту**| | |
|**1.2**|**Машинне навчання (DL): модель, навчання, інференс. Види машинного навчання**| | |
|**1.3**|**[Датасет](/01_03_DATASET/Lec_01_03_.pdf). Поняття датасету. Організація датасету для машинного навчання. Генерація типових датасетів за допомогою Scikit-Learn**|[IRIS](/01_03_DATASET/CODE_1/Lec_01_03_Exmpl_1_IRIS.md) [Blobs](/01_03_DATASET/CODE_3/Lec_01_03_Exmpl_3_Blobs.md)|[SciKit](https://scikit-learn.org/stable/datasets.html) [TensorFlow](https://www.tensorflow.org/datasets/catalog/overview#all_datasets)|


### **Частина 2. Навчання з вчителем (Unsupervised Learning)**

### Лекція 2.1. Регресія. Загальне визначення  задачі регресії. Типові постановки задачі регресії.

### Лекція 2.2. Оцінка якості вирішення задачі регресії. Огляд методів вирішення задачі регресії.

### Лекція 2.3. Приклад вирішення задачі лінійної регресії (Scikit-learn)

### Лекція 2.4. Приклад вирішення задачі поліноміальної регресії (Scikit-learn)

### Лекція 2.5. Класифікація. Загальна визначення  задач класифікації. Типові постановки задачі регресії.

### Лекція 2.6. Оцінка якості вирішення задачі класифікації. Огляд методів вирішення задачі класифікації.

### Лекція 2.7. Метод  kNN. Приклад вирішення задачі класифікації за допомогою kNN (Scikit-learn)

### Лекція 2.8. Метод  SVM. Приклад вирішення задачі класифікації за допомогою SVM (Scikit-learn)

### **Частина 3. Навчання без вчителя (самонавчання, Unsupervised Learning)**

### Лекція 3.1. Кластеризація. Загальна визначення  задач кластеризації. Типові варіанти постаноки задачі кластеризації.

### Лекція 3.2.  Оцінка якості вирішення задачі кластеризації . Огляд методів вирішення задачі кластеризації .

### Лекція 3.3.  Метод k-means.  Приклад вирішення задачі кластеризації  за допомогою k-means (Scikit-learn)

### Лекція 3.4.  Метод DBSCAN.  Приклад вирішення задачі кластеризації  за допомогою DBSCAN (Scikit-learn)

### **Частина 4. Навчання з  підкріпленням (Reinforcement Learning)**

### Лекція 4.1. Вступ до навчання з підкрипленням. Головні концепції. Агенти.

### Лекція 4.2. Метод Монте-Карло. Приклад використання методу Монтк-Карло вирішення задачі торії ігор (Python)

### **Частина 5. Глибоке навчання (Deep Learning)**

### Лекція 5.1.  Загальні відомості щодо нервової системи живих організмів. Природний нейрон. Синоптичний зв'язок нейронів. Правило Хебба. Штучний нейрон. Функція активації

### Лекція 5.2. Нейронні мережі. Нейронна мережа з одним прихованим шаром - персептрон.  Навчання персептрону. Приклад вирішення задачі класифікації за допомогою персептрону  (Python, Numpy)

### Лекція 5.3.  Багатошаровий персептрон (MLP). Загальний підхід до навчання MLP. Пряме розповсюдження.  Функція похибки. Зворотне розповсюдження.

### Лекція 5.4.  Градієнтний метод зменшення похибки навчання. Автоматичне обчислення  компонент градієнту. Основи оптимізації градієнтного спуску.  

### Лекція 5.5.  Основи побудови нейронних мереж з використанням модуля NumPy.

### Лекція 5.6.  Вирішення задачі класифікації за допомогою MLP. Приклад класифікації рукописних цифр (датасет MNIST, Python, Numpy)) .  

### Лекція 5.7. Сучасні системи штучного інтелекту, їх архітектури. Досягнення, перспективи, виклики.

### **Частина 6. Високорівнева мова проограмування Python**
### Лекція 6.1. Базові елементи високорівневої мови програмування.
### Лекція 6.2. Загальні поняття колекції та складних структур даних.
### Лекція 6.3. Файлові об’єкти. Визначення загальної структури програми.
### Лекція 6.4. Функціональне програмування.
### Лекція 6.5. Інтерпретація скриптів. Модулі та типові пакети.
### Лекція 6.6. Об’єктно-орієнтоване програмування. Проектування класів.
### Лекція 6.7. Можливості перевантаження операторів. Визначення понять об’єктів ітерування, ітератора та генератора.
### Лекція 6.8. Убудовані функції та вбудовані класи виняткових ситуацій.
### Лекція 6.9. Базові бібліотечні модулі. Пакети для роботи зі штучним інтелектом.

### **Частина 7. TensorFlow | KERAS**
### Лекція 7.1.  Бібліотека TensorFlow.  Архітектура. Тензорні  об'єкти. Створення тензорів. Індексація тензорів.
### Лекція 7.2.Бібліотека TensorFlow.  Базові операції із тензорами.
### Лекція 7.3. Бібліотека TensorFlow.   Поняття обчислювального графу. Використання графу для обчислень компонент градієнту під час зворотного поширення помилки. Типи обчислювальних графів, режими виконання. Створення "градієнтної стрічки"
### Лекція 7.4. Бібліотека TensorFlow.  Загальна організація процесу навчання моделі. Мінімізація похибки навчання методом градієнтного спуску.
### Лекція 7.5. Бібліотека TensorFlow.  Оптимізатори градієнтного спуску
### Лекція 7.6. Датасети. Ознаки, мітки. Пакети даних (batch).  Тренувальний набір даних (training set). Валідаційний набір даних (validation set). Тестувальний набір даних (testing set). Типові датасети бібліотек Scikit-learn.
### Лекція 7.7. Бібліотека TensorFlow.  Вбудовані датасети та засоби TF доступу до даних.
### Лекція 7.8. Підготовка даних для використання в навчанні моделей. Типи даних. Кодування даних. Очищення даних. Оцінка якості даних.
### Лекція 7.9. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом kNN TensorFlow.
### Лекція 7.10. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом SVM  TensorFlow.
### Лекція 7.11. Вирішення задачі кластеризації шляхом самонавчання моделі за алгоритмом DBSCAN засобами TensorFlow.
### Лекція 7.12. Бібліотека KERAS.  Шари та моделі.
### Лекція 7.13.  Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.
### Лекція 7.14. Бібліотека KERAS.  Вирішення задачі багато класової класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.

## Рекомендована література
### [Основна](ADDONS/Lit_Main.md)
### [Додаткова](ADDONS/Lit_Add.md)

## Матеріали включають

1. Теоретичні відомості щодо теми, що розглядається, достатні для оволодіння базовими питаннями означеної теми

2. Практичну реалізацію алгоритмів, що вивчаються на мові Pyton з використання відповідних бібліотек (Scikit-learn, Pandas, Tesorflow, Keras)

3. Приклади коду та блокноти  Jupyter, які містять вказівки, що полегшують розуміння складних концепцій і експериментування з різними техніками.

4. Посилання на додаткові ресурси (статті, навчальні посібники та набори даних).
