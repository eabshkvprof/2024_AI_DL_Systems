# +СХЕМОКОНСПЕКТ ЛЕКЦІЙ за дисципліною "**Методи та системи штучного інтелекту**"

Спеціальності

- 121 Інженерія програмного забезпечення

- 122 Комп’ютерні науки

- 123 Комп’ютерна інженерія

- 125 Кібербезпека



## Частина 1. Штучний інтелект та машинне навчання

Лекція 1. Введення в штучний інтелект. Історичний огляд, персоналії. Огляд завдань царині штучного інтелекту. 

Лекція 2. Машинне навчання: модель, навчання, інференс. Види машинного навчання.  

Лекція 3. Датасет. Поняття датасету. Організація дадасету для машинного навчання. Приклади (Scikit-Learn).

## Частина 2. Навчання з вчителем

Лекція 4. Регресія. Загальне визначення  задачі регресії. Типові постановки задачі регресії. 

Лекція 5. Оцінка якості вирішення задачі регресії. Огляд методів вирішення задачі регресії.

Лекція 6. Приклад вирішення задачі лінійної регресії (Scikit-learn)

Лекція 7. Приклад вирішення задачі поліноміальної регресії (Scikit-learn)

Лекція 8. Класифікація. Загальна визначення  задач класифікації. Типові постановки задачі регресії. 

Лекція 8. Оцінка якості вирішення задачі класифікації. Огляд методів вирішення задачі класифікації.

Лекція 9. Метод  kNN. Приклад вирішення задачі класифікації за допомогою kNN (Scikit-learn)

Лекція 10. Метод  SVM. Приклад вирішення задачі класифікації за допомогою SVM (Scikit-learn)

## Частина 3. Навчання без вчителя (самонавчання)

Лекція 11. Кластеризація. Загальна визначення  задач кластеризації. Типові варіанти постаноки задачі кластеризації.

Лекція 12.  Оцінка якості вирішення задачі кластеризації . Огляд методів вирішення задачі кластеризації .

Лекція 13.  Метод k-means.  Приклад вирішення задачі кластеризації  за допомогою k-means (Scikit-learn)

Лекція 14.  Метод DBSCAN.  Приклад вирішення задачі кластеризації  за допомогою DBSCAN (Scikit-learn)

## Частина 4. Навчання з  підкріпленням

Лекція 15.

Лекція 16. 

Лекція 17. 

Лекція 18. 

## Частина 5. Глибоке навчання

Лекція 18.  Загальні відомості щодо нервової системи живих організмів. Природний нейрон. Синоптичний зв'язок нейронів. Правило Хебба. Штучний нейрон. Функція активації 

Лекція 19. Нейронні мережі. Нейронна мережа з одним прихованим шаром - персептрон.  Навчання персептрону. Приклад вирішення задачі класифікації за допомогою персептрону  (Python, Numpy)

Лекція 20.  Багатошаровий персептрон (MLP). Загальний підхід до навчання MLP. Пряме розповсюдження.  Функція похибки. Зворотне розповсюдження. 

Лекція 21.  Градієнтний метод зменшення похибки навчання. Автоматичне обчислення  компонент градієнту. Основи оптимізації градієнтного спуску.  

Лекція 22.  Основи побудови нейронних мереж з використанням модуля NumPy.

Лекція 23.  Вирішення задачі класифікації за допомогою MLP. Приклад класифікації рукописних цифр (датасет MNIST, Python, Numpy)) .  

Лекція 24. Сучасні системи штучного інтелекту, їх архітектури. Досягнення, перспективи, виклики. 









Тема 9. Застосування сучасних технологій програмування в галузі штучного інтелекту. Базові елементи високорівневої мови програмування.

Тема 10. Загальні поняття колекції та складних структур даних.

Тема 11. Файлові об’єкти. Визначення загальної структури програми.

Тема 12. Функціональне програмування. 

Тема 13. Інтерпретація скриптів. Модулі та типові пакети. 

Тема 14. Об’єктно-орієнтоване програмування. Проектування класів.

Тема 15. Можливості перевантаження операторів. Визначення понять об’єктів ітерування, ітератора та генератора.

Тема 16. Убудовані функції та вбудовані класи виняткових ситуацій.

Тема 17. Базові бібліотечні модулі. Пакети для роботи зі штучним інтелектом.

Тема 18. Засоби візуалізації даних.

Тема 19. Використання системи контролю версій для створення проектів штучного інтелекту.

Тема 20. Загальні поняття якості та тестування програмного забезпечення штучного інтелекту.

Тема 21. Введення в штучні нейронні мережі.

Тема 22. Основи побудови нейронних мереж з використанням модуля NumPy.



## Частина 3. Програмні засоби ШІ ЧАСТЬ МОЯ



1. Сучасні технологій програмування в галузі штучного інтелекту. Високо рівневі програмні засоби побудови систем штучного інтелекту (огляд)
2. Бібліотека TensorFlow.  Архітектура. Тензорні  об'єкти. Створення тензорів. Індексація тензорів. 
3. Бібліотека TensorFlow.  Базові операції із тензорами. 
4. Бібліотека TensorFlow.   Поняття обчислювального графу. Використання графу для обчислень компонент градієнту під час зворотного поширення помилки. Типи обчислювальних графів, режими виконання. Створення "градієнтної стрічки"
5. Бібліотека TensorFlow.  Загальна організація процесу навчання моделі. Мінімізація похибки навчання методом градієнтного спуску.
6. Бібліотека TensorFlow.  Оптимізатори градієнтного спуску
7. Датасети. Ознаки, мітки. Пакети даних (batch).  Тренувальний набір даних (training set). Валідаційний набір даних (validation set). Тестувальний набір даних (testing set). Типові датасети бібліотек Scikit-learn.
8. Бібліотека TensorFlow.  Вбудовані датасети та засоби TF доступу до даних.
9. Підготовка даних для використання в навчанні моделей. Типи даних. Кодування даних. Очищення даних. Оцінка якості даних.
10. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом kNN засобами Scikit-learn  та  TensorFlow.
11. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом SVM  засобами Scikit-learn  та  TensorFlow.
12. Вирішення задачі кластеризації шляхом самонавчання моделі за алгоритмом DBSCAN засобами Scikit-learn  та  TensorFlow.
13. Функції похибки. Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу одношаровий персептрон засобами Numpy.
14. Бібліотека KERAS.  Шари та моделі.
15. Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.
16. Бібліотека KERAS.  Вирішення задачі багато класової класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.



-----------



Широке охоплення алгоритмів: досліджуйте широкий спектр алгоритмів ML, включаючи, але не обмежуючись, лінійну регресію, дерева рішень, опорні векторні машини, нейронні мережі, методи кластеризації тощо.



Лекційний матеріал  включає

1. Теоретичні відомості щодо теми, що розглядається, достатні для оволодіння ....

2. Практичну реалізацію алгоритмів, що вивчаються на мові Pyton з використання відповідних бібліотек (Scikit-learn, Pandas, Tesorflow, Keras)

3. Приклади коду та блокноти  Jupyter, які містять вказівки, що полегшують розуміння складних концепцій і експериментування з різними техніками.

4. Посилання на додаткові ресурси (статті, навчальні посібники та набори даних).

   

