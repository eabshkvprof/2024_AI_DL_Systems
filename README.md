<p align="center"><h1> ОСНОВИ СИСТЕМ ШТУЧНОГО ІНТЕЛЕКТУ, НЕЙРОННИХ МЕРЕЖ та ГЛИБОКОГО НАВЧАННЯ<h1></p>

<p align="center"><h2> ЛЕКЦІЙНИЙ МАТЕРІАЛ</h2></p>

**Надані матеріали охоплюють шрокий спектр концепцій, методів та алгоритмів ML, DL, NN, що дозволяє оволодіти знаннями відповідного профілю на першому (бакалаврському) рівні.**

<p align="center"><h2>Орієнтовано на спеціальності:</h2></p>

- ***121 Інженерія програмного забезпечення***
- ***122 Комп’ютерні науки***
- ***123 Комп’ютерна інженерія***
- ***125 Кібербезпека***

<details>
<summary> <h2> Частина 1. Штучний інтелект та машинне навчання (AI, DL) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**1.1**|**Введення в штучний інтелект (AI). Історичний огляд, персоналії. Огляд завдань царині штучного інтелекту**| | |
|**1.2**|**Машинне навчання (DL): модель, навчання, інференс. Види машинного навчання**| | |
|**1.3**|**[Датасет](/01_03_DATASET/Lec_01_03_.pdf). Поняття датасету. Організація датасету для машинного навчання. Генерація типових датасетів за допомогою Scikit-Learn**|[IRIS](/01_03_DATASET/CODE_1/Lec_01_03_Exmpl_1_IRIS.md) [Blobs](/01_03_DATASET/CODE_3/Lec_01_03_Exmpl_3_Blobs.md)|[SciKit](https://scikit-learn.org/stable/datasets.html) [TensorFlow](https://www.tensorflow.org/datasets/catalog/overview#all_datasets)|

</details>

<details>
<summary> <h2> Частина 2. Навчання з вчителем (Unsupervised Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**2.1**|**Регресія. Загальне визначення  задачі регресії. Типові постановки задачі регресії**| | |
|**2.2**|**Оцінка якості вирішення задачі регресії. Огляд методів вирішення задачі регресії**| | |
|**2.3**|**Приклад вирішення задачі лінійної регресії (Scikit-learn)**| | |
|**2.4**|**Приклад вирішення задачі поліноміальної регресії (Scikit-learn)**| | |
|**2.5**|**Класифікація. Загальна визначення  задач класифікації. Типові постановки задачі класифікації**| | |
|**2.6**|**Оцінка якості вирішення задачі класифікації. Огляд методів вирішення задачі класифікації**| | |
|**2.7**|**Метод  kNN. Приклад вирішення задачі класифікації за допомогою kNN (Scikit-learn)**| | |
|**2.8**|**Метод  SVM. Приклад вирішення задачі класифікації за допомогою SVM (Scikit-learn)**| | |

</details>

<details>
<summary> <h2> Частина 3. Навчання без вчителя (самонавчання, Unsupervised Learning) </h2> </summary>

| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**3.1**|**Кластеризація. Загальна визначення  задач кластеризації. Типові варіанти постаноки задачі кластеризації**| | |
|**3.2**|**Оцінка якості вирішення задачі кластеризації. Огляд методів вирішення задачі кластеризації**| | |
|**3.3**|**Метод k-means.  Приклад вирішення задачі кластеризації  за допомогою k-means (Scikit-learn)**| | |
|**3.4**|**Метод DBSCAN.  Приклад вирішення задачі кластеризації  за допомогою DBSCAN (Scikit-learn)**| | |

</details>

<details>
<summary> <h2>
Частина 4. Навчання з  підкріпленням (Reinforcement Learning) </h2> </summary>
| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**4.1**|**Вступ до навчання з підкрипленням. Головні концепції. Агенти.**| | |
|**4.2**|**Метод Монте-Карло. Приклад використання методу Монтк-Карло вирішення задачі торії ігор (Python)**| | |

</details>

<details>
<summary> <h2> Частина 5. Глибоке навчання (Deep Learning) </h2> </summary>
| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**5.1**|**Загальні відомості щодо нервової системи живих організмів. Природний нейрон. Синоптичний зв'язок нейронів. Правило Хебба. Штучний нейрон. Функція активації**| | |
|**5.2**|**Нейронні мережі. Нейронна мережа з одним прихованим шаром - персептрон.  Навчання персептрону. Приклад вирішення задачі класифікації за допомогою персептрону  (Python, Numpy)**| | |
|**5.3**|**Багатошаровий персептрон (MLP). Загальний підхід до навчання MLP. Пряме розповсюдження.  Функція похибки. Зворотне розповсюдження.**| | |
|**5.4**|**Градієнтний метод зменшення похибки навчання. Автоматичне обчислення  компонент градієнту. Основи оптимізації градієнтного спуску.**| | |
|**5.5**|**Основи побудови нейронних мереж з використанням модуля NumPy.**| | |
|**5.6**|**Вирішення задачі класифікації за допомогою MLP. Приклад класифікації рукописних цифр (датасет MNIST, Python, Numpy)**| | |
|**5.7**|**Сучасні системи штучного інтелекту,  архітектури систем AI. Досягнення, перспективи, виклики.**| | |

</details>

<details>
<summary> <h2>
Частина 6. Високорівнева мова проограмування Python  </h2> </summary>
| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**6.1**|**Базові елементи високорівневої мови програмування**| | |
|**6.2**|**Загальні поняття колекції та складних структур даних.**| | |
|**6.3**|**Файлові об’єкти. Визначення загальної структури програми.**| | |
|**6.4**|**Функціональне програмування.**| | |
|**6.5**|**Інтерпретація скриптів. Модулі та типові пакети.**| | |
|**6.6**|**Об’єктно-орієнтоване програмування. Проектування класів.**| | |
|**6.7**|**Можливості перевантаження операторів. Визначення понять об’єктів ітерування, ітератора та генератора.**| | |
|**6.8**|**Убудовані функції та вбудовані класи виняткових ситуацій.**| | |
|**6.9**|**Базові бібліотечні модулі. Пакети для роботи зі штучним інтелектом.**| | |

</details>

<details>
<summary> <h2>
Частина 7. Бібліотеки TensorFlow та KERAS  </h2> </summary>
| Лекція |Тема | Код | Посилання|
| -------|------ | ------ | ------ |
|**7.1**|**TensorFlow.  Архітектура. Тензорні  об'єкти. Створення тензорів. Індексація тензорів.**| | |
|**7.2**|**TensorFlow.  Базові операції із тензорами**| | |
|**7.3**|**TensorFlow.   Поняття обчислювального графу. Використання графу для обчислень компонент градієнту під час зворотного поширення помилки. Типи обчислювальних графів, режими виконання. Створення "градієнтної стрічки"**| | |
|**7.4**|**TensorFlow.  Загальна організація процесу навчання моделі. Мінімізація похибки навчання методом градієнтного спуску.**| | |
|**7.5**|**TensorFlow.  Оптимізатори градієнтного спуску**| | |
|**7.6**|**Датасети. Ознаки, мітки. Пакети даних (batch).  Тренувальний набір даних (training set). Валідаційний набір даних (validation set). Тестувальний набір даних (testing set)**| | |
|**7.7**|**TensorFlow.  Вбудовані датасети та засоби TF доступу до даних.**| | |
|**7.8**|**Підготовка даних для використання в навчанні моделей. Типи даних. Кодування даних. Очищення даних. Оцінка якості даних**| | |
|**7.9**|**Вирішення задачі класифікації шляхом навчання моделі за алгоритмом kNN TensorFlow.**| | |
|**7.10**|**Вирішення задачі класифікації шляхом навчання моделі за алгоритмом SVM  TensorFlow**| | |
|**7.11**|**Вирішення задачі кластеризації шляхом самонавчання моделі за алгоритмом DBSCAN засобами TensorFlow**| | |
|**7.12**|**KERAS.  Шари та моделі. Робота **| | |
|**7.13**|**Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS**| | |
|**7.114**|**Вирішення задачі багато класової класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS**| | |

</details>

<p align="center"><h2> Рекомендована література </h2></p>

- [Основна](ADDONS/Lit_Main.md)

- [Додаткова](ADDONS/Lit_Add.md)

<p align="center"><h2>  Матеріали включають </h2></p>

1. Теоретичні відомості щодо теми, що розглядається, достатні для оволодіння базовими питаннями означеної теми

2. Практичну реалізацію алгоритмів, що вивчаються на мові Pyton з використання відповідних бібліотек (Scikit-learn, Pandas, Tesorflow, Keras)

3. Приклади коду та блокноти  Jupyter, які містять вказівки, що полегшують розуміння складних концепцій і експериментування з різними техніками.

4. Посилання на додаткові ресурси (статті, навчальні посібники та набори даних).
