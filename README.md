# **ЛЕКЦІЙНИЙ МАТРІАЛ**
# за дисципліною "**Методи та системи штучного інтелекту**"

## Спеціальності
- 121 Інженерія програмного забезпечення
- 122 Комп’ютерні науки
- 123 Комп’ютерна інженерія
- 125 Кібербезпека

## Надані матеріали охоплюють шрокий спектр концепцій, методів та алгоритмів ML, DL, NN, що дозволяє оволодіти знаннями відповідного проофілю на різних рівнях.

## Частина 1. Штучний інтелект та машинне навчання (AI, DL)

### Лекція 1. Введення в штучний інтелект (AI). Історичний огляд, персоналії. Огляд завдань царині штучного інтелекту.

### Лекція 2. Машинне навчання (DL): модель, навчання, інференс. Види машинного навчання.  

### Лекція 3. Датасет. Поняття датасету. Організація дадасету для машинного навчання. Приклади (Scikit-Learn).

## Частина 2. Навчання з вчителем (Unsupervised Learning)

### Лекція 4. Регресія. Загальне визначення  задачі регресії. Типові постановки задачі регресії.

### Лекція 5. Оцінка якості вирішення задачі регресії. Огляд методів вирішення задачі регресії.

### Лекція 6. Приклад вирішення задачі лінійної регресії (Scikit-learn)

### Лекція 7. Приклад вирішення задачі поліноміальної регресії (Scikit-learn)

### Лекція 8. Класифікація. Загальна визначення  задач класифікації. Типові постановки задачі регресії.

### Лекція 9. Оцінка якості вирішення задачі класифікації. Огляд методів вирішення задачі класифікації.

### Лекція 10. Метод  kNN. Приклад вирішення задачі класифікації за допомогою kNN (Scikit-learn)

### Лекція 11. Метод  SVM. Приклад вирішення задачі класифікації за допомогою SVM (Scikit-learn)

## Частина 3. Навчання без вчителя (самонавчання, Unsupervised Learning)

### Лекція 12. Кластеризація. Загальна визначення  задач кластеризації. Типові варіанти постаноки задачі кластеризації.

### Лекція 13.  Оцінка якості вирішення задачі кластеризації . Огляд методів вирішення задачі кластеризації .

### Лекція 14.  Метод k-means.  Приклад вирішення задачі кластеризації  за допомогою k-means (Scikit-learn)

### Лекція 15.  Метод DBSCAN.  Приклад вирішення задачі кластеризації  за допомогою DBSCAN (Scikit-learn)

## Частина 4. Навчання з  підкріпленням (Reinforcement Learning)

### Лекція 16. Вступ до навчання з підкрипленням. Головні концепції. Агенти.

### Лекція 17. Метод Монте-Карло. Приклад використання методу Монтк-Карло вирішення задачі торії ігор (Python)

## Частина 5. Глибоке навчання (Deep Learning)

### Лекція 18.  Загальні відомості щодо нервової системи живих організмів. Природний нейрон. Синоптичний зв'язок нейронів. Правило Хебба. Штучний нейрон. Функція активації

### Лекція 19. Нейронні мережі. Нейронна мережа з одним прихованим шаром - персептрон.  Навчання персептрону. Приклад вирішення задачі класифікації за допомогою персептрону  (Python, Numpy)

### Лекція 20.  Багатошаровий персептрон (MLP). Загальний підхід до навчання MLP. Пряме розповсюдження.  Функція похибки. Зворотне розповсюдження.

### Лекція 21.  Градієнтний метод зменшення похибки навчання. Автоматичне обчислення  компонент градієнту. Основи оптимізації градієнтного спуску.  

### Лекція 22.  Основи побудови нейронних мереж з використанням модуля NumPy.

### Лекція 23.  Вирішення задачі класифікації за допомогою MLP. Приклад класифікації рукописних цифр (датасет MNIST, Python, Numpy)) .  

### Лекція 24. Сучасні системи штучного інтелекту, їх архітектури. Досягнення, перспективи, виклики.

## Частина 6. Високорівнева мова проограмування Python
### Лекція 6.1. Базові елементи високорівневої мови програмування.
### Лекція 6.2. Загальні поняття колекції та складних структур даних.
### Лекція 6.3. Файлові об’єкти. Визначення загальної структури програми.
### Лекція 6.4. Функціональне програмування.
### Лекція 6.5. Інтерпретація скриптів. Модулі та типові пакети.
### Лекція 6.6. Об’єктно-орієнтоване програмування. Проектування класів.
### Лекція 6.7. Можливості перевантаження операторів. Визначення понять об’єктів ітерування, ітератора та генератора.
### Лекція 6.8. Убудовані функції та вбудовані класи виняткових ситуацій.
### Лекція 6.9. Базові бібліотечні модулі. Пакети для роботи зі штучним інтелектом.


## Частина 7. TensorFlow | KERAS
### Лекція 7.1.  Бібліотека TensorFlow.  Архітектура. Тензорні  об'єкти. Створення тензорів. Індексація тензорів.
### Лекція 7.2.Бібліотека TensorFlow.  Базові операції із тензорами.
### Лекція 7.3. Бібліотека TensorFlow.   Поняття обчислювального графу. Використання графу для обчислень компонент градієнту під час зворотного поширення помилки. Типи обчислювальних графів, режими виконання. Створення "градієнтної стрічки"
### Лекція 7.4. Бібліотека TensorFlow.  Загальна організація процесу навчання моделі. Мінімізація похибки навчання методом градієнтного спуску.
### Лекція 7.5. Бібліотека TensorFlow.  Оптимізатори градієнтного спуску
### Лекція 7.6. Датасети. Ознаки, мітки. Пакети даних (batch).  Тренувальний набір даних (training set). Валідаційний набір даних (validation set). Тестувальний набір даних (testing set). Типові датасети бібліотек Scikit-learn.
### Лекція 7.7. Бібліотека TensorFlow.  Вбудовані датасети та засоби TF доступу до даних.
### Лекція 7.8. Підготовка даних для використання в навчанні моделей. Типи даних. Кодування даних. Очищення даних. Оцінка якості даних.
### Лекція 7.9. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом kNN TensorFlow.
### Лекція 7.10. Вирішення задачі класифікації шляхом навчання моделі за алгоритмом SVM  TensorFlow.
### Лекція 7.11. Вирішення задачі кластеризації шляхом самонавчання моделі за алгоритмом DBSCAN засобами TensorFlow.
### Лекція 7.12. Бібліотека KERAS.  Шари та моделі.
### Лекція 7.13.  Вирішення задачі бінарної класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.
### Лекція 7.14. Бібліотека KERAS.  Вирішення задачі багато класової класифікації шляхом навчання нейронної мережі класу багатошаровий персептрон (MLP) засобами  TensorFlow/KERAS.



## Матріали включають

1. Теоретичні відомості щодо теми, що розглядається, достатні для оволодіння базовими питаннями означеної теми

2. Практичну реалізацію алгоритмів, що вивчаються на мові Pyton з використання відповідних бібліотек (Scikit-learn, Pandas, Tesorflow, Keras)

3. Приклади коду та блокноти  Jupyter, які містять вказівки, що полегшують розуміння складних концепцій і експериментування з різними техніками.

4. Посилання на додаткові ресурси (статті, навчальні посібники та набори даних).
